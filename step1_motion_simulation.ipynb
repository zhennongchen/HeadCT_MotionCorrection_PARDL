{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "You should prepare the following things before running this step. Please refer to the `example_data` folder for guidance:\n",
    "\n",
    "1. **NIfTI images** of head CT resampled to a voxel size of **[1,1,2.5] mmÂ³**.  \n",
    "   - Please refer to ```example_data/data/raw_data``` for an example\n",
    "\n",
    "---\n",
    "\n",
    "## Simulate motion-corrupted image and its partial angle reconstruction (PAR) for supervised training\n",
    "\n",
    "In this script, we apply simulated motion to a motion-free head CT scan and therefore record the motion parameters (used as ground truth in model training) and generate motion-corrupted images as well as partial angle reconstrutions (used as model input).\n",
    "- motion parameter and image example: ```example_data/data/simulated_data_3D_spline_6degrees```.\n",
    "    \n",
    "- PAR example: ```example_data/data/PAR_3D_spline_6degrees```\n",
    "\n",
    "---\n",
    "\n",
    "### Docker environment\n",
    "1. Please use `docker/docker_tensorflow`, it will build a tensorflow docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os, sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import glob as gb\n",
    "import nibabel as nb\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "import HeadCT_MotionCorrection_PARDL.motion_simulator.motion_simulation.ct_basic as ct\n",
    "import HeadCT_MotionCorrection_PARDL.functions_collection as ff\n",
    "import HeadCT_MotionCorrection_PARDL.motion_simulator.transformation as transform\n",
    "import HeadCT_MotionCorrection_PARDL.Data_processing as dp\n",
    "import ct_projector.projector.cupy as ct_projector\n",
    "\n",
    "main_path = '/mnt/camca_NAS/motion_correction/'  # replace with your main path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define motion range:\n",
    "motion_type = '3D_spline_6degrees'\n",
    "save_folder_img = os.path.join(main_path,'example_data/data','simulated_data_'+motion_type)\n",
    "save_folder_PAR = os.path.join(main_path,'example_data/data','PAR_'+motion_type)\n",
    "ff.make_folder([save_folder_img, save_folder_PAR])\n",
    "\n",
    "motion_dim = 3\n",
    "amplitude_max = 5\n",
    "displacement_max = 2.5\n",
    "change_direction_limit = 2\n",
    "CP_num = 5\n",
    "\n",
    "geometry = 'fan'\n",
    "total_view = 1400  ### 2340 views by default\n",
    "gantry_rotation_time = 500 #unit ms, 500ms by default\n",
    "view_increment = 28 # increment in gantry views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# define the patient list\n",
    "data_folder = os.path.join(main_path,'example_data/data/raw_data/')\n",
    "patient_list= ff.find_all_target_files(['*/*'],data_folder)\n",
    "print(len(patient_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### motion simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient:  MO101701M000001 MO001A000001\n",
      "nib image shape:  (66, 220, 220)  spacing:  [2.5, 1.0, 1.0]\n",
      "\n",
      " 1 random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Documents/HeadCT_MotionCorrection_PARDL/motion_simulator/transformation/rotation_matrix_from_angle.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(\n",
      "/workspace/Documents/HeadCT_MotionCorrection_PARDL/motion_simulator/transformation/rotation_matrix_from_angle.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(\n",
      "/workspace/Documents/HeadCT_MotionCorrection_PARDL/motion_simulator/transformation/rotation_matrix_from_angle.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 220, 66)\n",
      "(25, 220, 220, 50)\n",
      "(25, 110, 110, 50)\n",
      "crop final image shape:  (25, 128, 128, 50)\n"
     ]
    }
   ],
   "source": [
    "for p in patient_list:\n",
    "    patient_subid = os.path.basename(p)\n",
    "    patient_id = os.path.basename(os.path.dirname(p))\n",
    "\n",
    "    print('patient: ',patient_id, patient_subid)\n",
    "    \n",
    "    save_folder_img_patient = os.path.join(save_folder_img,patient_id,patient_subid)\n",
    "    ff.make_folder([os.path.dirname(save_folder_img_patient), save_folder_img_patient])\n",
    "\n",
    "    img_file = os.path.join(p,'img_2.5mm.nii.gz')\n",
    "\n",
    "    img,spacing,img_affine = ct.basic_image_processing(img_file)\n",
    "\n",
    "    spacing = [2.5, 1.0, 1.0]\n",
    "    print('nib image shape: ',img.shape, ' spacing: ',spacing)\n",
    "\n",
    "    # define projectors\n",
    "    img = img[np.newaxis, ...]\n",
    "    projector = ct.define_forward_projector(img,spacing,total_view)\n",
    "    fbp_projector = ct.backprojector(img,spacing)\n",
    "\n",
    "\n",
    "    # very important - make sure that the arrays are saved in C order\n",
    "    cp.cuda.Device(0).use()\n",
    "    ct_projector.set_device(0)\n",
    "\n",
    "\n",
    "\n",
    "    # do simulation\n",
    "    L = np.arange(1,2)\n",
    "\n",
    "    for random_i in L:\n",
    "\n",
    "        t = np.linspace(0, gantry_rotation_time, CP_num, endpoint=True)\n",
    "\n",
    "        # create folder\n",
    "        if random_i == 0:\n",
    "            random_folder = os.path.join(save_folder_img_patient,'static')\n",
    "        else:\n",
    "            random_folder = os.path.join(save_folder_img_patient,'random_'+str(random_i))\n",
    "        ff.make_folder([random_folder, os.path.join(random_folder,'image_data')])\n",
    "\n",
    "        print('\\n',random_i  , 'random')\n",
    "\n",
    "\n",
    "        # use previous motion if available\n",
    "        saved_motion_parameter_file = os.path.join(random_folder,  'motion_parameters.npy')\n",
    "\n",
    "        if os.path.isfile(saved_motion_parameter_file) == 1:\n",
    "            previous_motion_parameter = np.load(saved_motion_parameter_file, allow_pickle = True)\n",
    "            amplitude_tx_mm = previous_motion_parameter[0,:][0]\n",
    "            amplitude_ty_mm = previous_motion_parameter[1,:][0]\n",
    "            amplitude_tz_mm = previous_motion_parameter[2,:][0]\n",
    "            amplitude_rx_degree = previous_motion_parameter[3,:][0]\n",
    "            amplitude_ry_degree = previous_motion_parameter[4,:][0]\n",
    "            amplitude_rz_degree = previous_motion_parameter[5,:][0]\n",
    "            sga = previous_motion_parameter[6,:][0]\n",
    "\n",
    "        else:\n",
    "            ValueError('no previous motion saved')\n",
    "            while True:\n",
    "                amplitude_tx_mm = transform.motion_control_point_generation(1, CP_num, amplitude_max, displacement_max, change_direction_limit, print_result = False)[:,0]\n",
    "                amplitude_ty_mm = transform.motion_control_point_generation(1, CP_num, amplitude_max, displacement_max, change_direction_limit, print_result = False)[:,0]\n",
    "                amplitude_tz_mm = transform.motion_control_point_generation(1, CP_num, amplitude_max, displacement_max, change_direction_limit, print_result = False)[:,0]\n",
    "                amplitude_rx_degree = transform.motion_control_point_generation(1, CP_num, amplitude_max, displacement_max, change_direction_limit, print_result = False)[:,0]\n",
    "                amplitude_ry_degree = transform.motion_control_point_generation(1, CP_num, amplitude_max, displacement_max, change_direction_limit, print_result = False)[:,0]\n",
    "                amplitude_rz_degree = transform.motion_control_point_generation(1, CP_num, amplitude_max, displacement_max, change_direction_limit, print_result = False)[:,0]\n",
    "                if np.max(abs(amplitude_rx_degree))+ np.max(abs(amplitude_ry_degree)) <= 7:\n",
    "                    print('rx+ry: ', np.max(abs(amplitude_rx_degree))+ np.max(abs(amplitude_ry_degree)))\n",
    "                    break\n",
    "\n",
    "            sga = int(np.random.uniform(0,90)) # starting gantry angle\n",
    "            if random_i == 0:\n",
    "                amplitude_tx_mm = [0, 0, 0, 0, 0]\n",
    "                amplitude_ty_mm = [0, 0, 0, 0, 0]\n",
    "                amplitude_tz_mm = [0, 0, 0, 0, 0]\n",
    "                amplitude_rx_degree = [0, 0, 0, 0, 0]\n",
    "                amplitude_ry_degree = [0, 0, 0, 0, 0]\n",
    "                amplitude_rz_degree = [0, 0, 0, 0, 0]\n",
    "\n",
    "            # save motion parameters\n",
    "            parameter_file = os.path.join(random_folder,'motion_parameters.txt')\n",
    "            ff.txt_writer(parameter_file,False,[t.tolist(),amplitude_tx_mm, amplitude_ty_mm, amplitude_tz_mm, amplitude_rx_degree, amplitude_ry_degree, amplitude_rz_degree, [sga],[total_view],[gantry_rotation_time]],['time_points','translation_x_CP','translation_y_CP','translation_z_CP', 'rotation_x_CP', 'rotation_y_CP','rotation_z_CP','starting_gantry_angle', 'total_projection_view','gantry_rotation_time(ms)'])\n",
    "\n",
    "            parameter_file = os.path.join(random_folder,'motion_parameters.npy')\n",
    "            np.save(parameter_file, np.array([[amplitude_tx_mm],[amplitude_ty_mm],[amplitude_tz_mm],[amplitude_rx_degree],[amplitude_ry_degree],[amplitude_rz_degree],[sga], [t], [total_view], [gantry_rotation_time]], dtype=object))\n",
    "\n",
    "\n",
    "\n",
    "        # prepare spline fit\n",
    "        spline_tx = transform.interp_func(t, np.asarray([i/spacing[1] for i in amplitude_tx_mm]))\n",
    "        spline_ty = transform.interp_func(t, np.asarray([i/spacing[2] for i in amplitude_ty_mm]))\n",
    "        spline_tz = transform.interp_func(t, np.asarray([i/spacing[0] for i in amplitude_tz_mm]))\n",
    "        spline_rx = transform.interp_func(t,np.asarray([i / 180 * np.pi for i in amplitude_rx_degree]))\n",
    "        spline_ry = transform.interp_func(t,np.asarray([i / 180 * np.pi for i in amplitude_ry_degree]))\n",
    "        spline_rz = transform.interp_func(t,np.asarray([i / 180 * np.pi for i in amplitude_rz_degree]))\n",
    "        angles = ff.get_angles_zc(total_view, 360 ,sga)\n",
    "\n",
    "        # generate forward projection\n",
    "        projection = ct.fp_w_spline_motion_model(img, projector, angles, spline_tx, spline_ty, spline_tz, spline_rx, spline_ry, spline_rz, geometry, total_view = total_view, gantry_rotation_time = gantry_rotation_time, slice_num = None, increment = view_increment, order = 3)\n",
    "\n",
    "        # # save fp\n",
    "        projection_save_version = nb.Nifti1Image(projection[:,:,0,:], img_affine)\n",
    "        nb.save(projection_save_version, os.path.join(random_folder,'projection.nii.gz'))\n",
    "        # projection = nb.load(os.path.join(random_folder,'projection.nii.gz')).get_fdata()\n",
    "        # projection = np.expand_dims(projection, axis=2)\n",
    "        # print('projection shape: ', projection.shape) \n",
    "\n",
    "        # # generate backprojection\n",
    "        recon = ct.filtered_backporjection(projection,angles,projector,fbp_projector, geometry, back_to_original_value=True)\n",
    "\n",
    "        # save recon\n",
    "        recon_nb_image = np.rollaxis(recon,0,3) \n",
    "        print(recon_nb_image.shape)\n",
    "        nb.save(nb.Nifti1Image(recon_nb_image,img_affine), os.path.join(random_folder,'image_data','recon.nii.gz'))\n",
    "        # only pick 50 slices\n",
    "        nb.save(nb.Nifti1Image(recon_nb_image[:,:,10:60],img_affine), os.path.join(random_folder,'image_data','recon_partial.nii.gz'))\n",
    "\n",
    "        # make PAR\n",
    "        if random_i == 0:\n",
    "            print('static, no need to make PAR')\n",
    "            continue\n",
    "\n",
    "        K = 12\n",
    "        save_folder2 = os.path.join(save_folder_PAR,patient_id, patient_subid, 'random_' + str(random_i),'slice_0_to_50')\n",
    "        ff.make_folder([os.path.join(save_folder_PAR,patient_id), os.path.join(save_folder_PAR,patient_id, patient_subid), os.path.join(save_folder_PAR,patient_id, patient_subid, 'random_' + str(random_i)), save_folder2])\n",
    "        \n",
    "        sinogram_segments, center_angle_index, num_angles_in_one_segment, segment_indexes = ct.divide_sinogram_new(projection, K , total_view)\n",
    "\n",
    "        PAR_collections = ct.make_PAR_new(sinogram_segments, segment_indexes, angles, img[0,...].shape, projector, fbp_projector, 'fan')\n",
    "\n",
    "        PAR_collections = np.rollaxis(PAR_collections,1,4)\n",
    "        # only pick 50 slices\n",
    "        PAR_collections = PAR_collections[:,:,:,10:60]\n",
    "        print(PAR_collections.shape)\n",
    "\n",
    "        PAR_collections_ds = block_reduce(PAR_collections, block_size=(1,2,2,1), func=np.mean)\n",
    "        print(PAR_collections_ds.shape)\n",
    "\n",
    "            \n",
    "        crop_img = np.zeros([2*K + 1, 128,128 , PAR_collections_ds.shape[-1]])\n",
    "\n",
    "        for j in range(0,PAR_collections_ds.shape[0]):\n",
    "            crop_img[j,...] = dp.crop_or_pad(PAR_collections_ds[j,...], [128,128,PAR_collections_ds.shape[-1] ], np.min(PAR_collections_ds[j,...]))\n",
    "\n",
    "        print('crop final image shape: ' ,crop_img.shape)\n",
    "\n",
    "        nb.save(nb.Nifti1Image(crop_img, img_affine), os.path.join(save_folder2,'PARs_ds_crop.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
