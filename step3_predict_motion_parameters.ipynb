{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "You should prepare the following things before running this step. Please refer to the `example_data` folder for guidance:\n",
    "\n",
    "1. **PAR images**\n",
    "   - the default dimension of model input is [25,128,128,15] where 25 is the number of PAR images, [128,128] is x-y-dimension, 15 is the number of slices\n",
    "\n",
    "2. **A patient list** that enumerates all your cases.  \n",
    "   - To understand the expected format, please refer to the file:  \n",
    "     `example_data/Patient_list/patient_list.xlsx`.\n",
    "\n",
    "---\n",
    "## Prediction\n",
    "The output is a (6,4) matrix, where 6 represents 6 motion parameters (tx, ty, tz, rx, ry, rz), and 4 represents 4 control points (each motion parameter is defined by 5 control points with the first one always 0, here we predict the rest 4).\n",
    "\n",
    "### Docker environment\n",
    "1. Please use `docker/docker_tensorflow`, it will build a tensorflow docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 17:39:16.724224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os, sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "import HeadCT_MotionCorrection_PARDL.STN.model_STN as model_STN\n",
    "import HeadCT_MotionCorrection_PARDL.STN.Generator_STN as Generator_STN\n",
    "import HeadCT_MotionCorrection_PARDL.Data_processing as dp\n",
    "import HeadCT_MotionCorrection_PARDL.functions_collection as ff\n",
    "from HeadCT_MotionCorrection_PARDL.Build_lists import Build_list\n",
    "\n",
    "main_path = '/mnt/camca_NAS/motion_correction/'  # replace with your main path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define trial name and set default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = 'PAR_model'\n",
    "\n",
    "CP_num = 5\n",
    "input_shape = (128,128,15,25)  # 128 for x dim, 128 for y dim, 15 for z dim (15 slices by default), 25 for the number of PAR images\n",
    "\n",
    "trial_folder = os.path.join(main_path, 'example_data/models', trial_name)\n",
    "save_folder = os.path.join(main_path, 'example_data/models', trial_name, 'predictions')\n",
    "ff.make_folder([save_folder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sheet = os.path.join(main_path,'example_data/Patient_list/patient_list.xlsx')\n",
    "b = Build_list.Build(data_sheet)\n",
    "\n",
    "_, patient_id_list_test, patient_subid_list_test, random_name_list_test,  start_slice_test, end_slice_test, _, _,  y_motion_param_test, x_par_image_test = b.__build__(batch_list = [0])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 17:39:21.586599: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-07-09 17:39:21.586796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2025-07-09 17:39:21.697475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-09 17:39:21.699662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:13:00.0 name: NVIDIA A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.49GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2025-07-09 17:39:21.699711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2025-07-09 17:39:21.699804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2025-07-09 17:39:21.699841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2025-07-09 17:39:21.699874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-07-09 17:39:21.699905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-07-09 17:39:21.699939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-07-09 17:39:21.699973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2025-07-09 17:39:21.699993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2025-07-09 17:39:21.700097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-09 17:39:21.702139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-09 17:39:21.704082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2025-07-09 17:39:21.704571: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-09 17:39:21.706507: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-07-09 17:39:21.706648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-09 17:39:21.708598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:13:00.0 name: NVIDIA A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.49GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2025-07-09 17:39:21.708622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2025-07-09 17:39:21.708646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2025-07-09 17:39:21.708666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2025-07-09 17:39:21.708684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-07-09 17:39:21.708702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-07-09 17:39:21.708719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-07-09 17:39:21.708748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2025-07-09 17:39:21.708767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2025-07-09 17:39:21.708864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-09 17:39:21.710884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-09 17:39:21.712835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2025-07-09 17:39:21.712879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2025-07-09 17:39:22.457884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-07-09 17:39:22.457940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2025-07-09 17:39:22.457954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2025-07-09 17:39:22.458283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-09 17:39:22.459861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-09 17:39:22.461162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-09 17:39:22.462393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 37458 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:13:00.0, compute capability: 8.0)\n"
     ]
    }
   ],
   "source": [
    "# create model architecture:\n",
    "model_inputs = [Input(input_shape)]\n",
    "model_outputs=[]\n",
    "tx, ty, tz, rx, ry, rz = model_STN.get_CNN(nb_filters = [16,32,64,128,256], dimension = 3, CP_num = CP_num)(model_inputs[0])\n",
    "model_outputs = [tx, ty, tz, rx , ry, rz]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find trained model files\n",
    "\n",
    "we recommend to predict using multiple models/checkpoints, since we find that averaging/using median across multiple models' results may improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "model_folder = os.path.join(trial_folder, 'models')\n",
    "model_files = ff.find_all_target_files(['*'],model_folder)\n",
    "\n",
    "print(len(model_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using each model\n",
    "for j in range(0,len(model_files)):\n",
    "    f = model_files[j]\n",
    "    print('loading model from: ', f)\n",
    "    model= Model(inputs = model_inputs,outputs = model_outputs)\n",
    "    model.load_weights(f)\n",
    "\n",
    "    for i in range(0, patient_id_list_test.shape[0]):\n",
    "        patient_id = patient_id_list_test[i]\n",
    "        patient_subid = patient_subid_list_test[i]\n",
    "        random_name = random_name_list_test[i]\n",
    "        print('processing patient: ', patient_id, patient_subid, random_name)\n",
    "\n",
    "        save_sub = os.path.join(save_folder, patient_id, patient_subid, random_name,'parameters' , 'slice_' + str(start_slice_test[i]) + '_to_' + str(start_slice_test[i] + 15))\n",
    "        ff.make_folder([os.path.join(save_folder,patient_id), os.path.join(save_folder,patient_id, patient_subid), os.path.join(save_folder, patient_id, patient_subid, random_name), os.path.dirname(save_sub), save_sub])\n",
    "        filename = 'model_' + str(j) + '.npy'\n",
    "\n",
    "        datagen = Generator_STN.DataGenerator(np.asarray([x_par_image_test[i]]),\n",
    "                                            np.asarray([y_motion_param_test[i]]),\n",
    "                                            np.asarray([start_slice_test[i]]),\n",
    "                                            np.asarray([end_slice_test[i]]),\n",
    "                                            start_slice_sampling = None,\n",
    "                                            patient_num = 1, \n",
    "                                            batch_size =1,\n",
    "                                            input_dimension = input_shape,\n",
    "                                            output_vector_dimension = (CP_num - 1,),\n",
    "                                            shuffle = False,augment = False,)\n",
    "        \n",
    "        tx, ty, tz, rx, ry, rz = model.predict_generator(datagen, verbose = 1, steps = 1,)  # unit is \"pixel\"\n",
    "        tx = np.reshape(np.asarray(tx),-1) *5\n",
    "        ty = np.reshape(np.asarray(ty),-1) *5\n",
    "        tz = np.reshape(np.asarray(tz), -1) *2  # *5 for thin slice, *2 for 2.5mm\n",
    "        rx = np.reshape(np.asarray(rx),-1)  *5\n",
    "        ry = np.reshape(np.asarray(ry),-1)  *5\n",
    "        rz = np.reshape(np.asarray(rz),-1)  *5\n",
    "        predict = np.reshape(np.concatenate([tx, ty, tz, rx,ry, rz], axis = -1), -1)\n",
    "\n",
    "        # save\n",
    "        np.save(os.path.join(save_sub,filename), np.reshape(predict,(6,-1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing patient:  MO101701M000006 MO001A000007 random_1\n",
      "motion parameters shape : (17, 6, 4)\n",
      "processing patient:  MO101701M000006 MO001A000007 random_1\n",
      "motion parameters shape : (17, 6, 4)\n",
      "processing patient:  MO101701M000006 MO001A000007 random_1\n",
      "motion parameters shape : (17, 6, 4)\n"
     ]
    }
   ],
   "source": [
    "# use all predicted motion parameters to get final prediction via averaging or median\n",
    "for i in range(0, patient_id_list_test.shape[0]):\n",
    "    patient_id = patient_id_list_test[i]\n",
    "    patient_subid = patient_subid_list_test[i]\n",
    "    random_name = random_name_list_test[i]\n",
    "    print('processing patient: ', patient_id, patient_subid, random_name)\n",
    "\n",
    "    start_slice = start_slice_test[i]\n",
    "    folder = os.path.join(save_folder, patient_id, patient_subid, random_name, 'parameters', 'slice_' + str(start_slice) + '_to_' + str(start_slice + 15))\n",
    "    files = ff.find_all_target_files(['model_*.npy'], folder)\n",
    "        \n",
    "    motion_params = np.zeros((len(files) , 6 , 4))\n",
    "    for j in range(0, len(files)):\n",
    "        f = files[j]\n",
    "        motion_params[j] = np.load(f, allow_pickle=True)\n",
    "\n",
    "    print('motion parameters shape :', motion_params.shape)\n",
    "\n",
    "    # average across first axis\n",
    "    motion_params_avg = np.median(motion_params, axis=0)\n",
    "    tx = motion_params_avg[0,:]\n",
    "    ty = motion_params_avg[1,:]\n",
    "    tz = motion_params_avg[2,:]\n",
    "    rx = motion_params_avg[3,:]\n",
    "    ry = motion_params_avg[4,:]\n",
    "    rz = motion_params_avg[5,:]\n",
    "\n",
    "    # save averaged motion parameters\n",
    "    np.save(os.path.join(folder, 'pred_final.npy'), motion_params_avg)\n",
    "\n",
    "    # # load ground truth\n",
    "    # gt = np.load(y_motion_param_test[i],allow_pickle = True)\n",
    "    # gt_tx = gt[0,:][0][1: CP_num]\n",
    "    # gt_ty = gt[1,:][0][1: CP_num]\n",
    "    # gt_tz = gt[2,:][0][1: CP_num]  / 2.5\n",
    "    # gt_rx = np.asarray(gt[3,:][0][1: CP_num])\n",
    "    # gt_ry= np.asarray(gt[4,:][0][1: CP_num])\n",
    "    # gt_rz = np.asarray(gt[5,:][0][1: CP_num]) \n",
    "\n",
    "    # print('tx: ', tx, ' gt tx:', gt_tx,  ' tx diff: ', np.abs(tx - gt_tx), ' in average: ', np.mean(np.abs(tx - gt_tx)), 'origin max: ',np.max(np.abs(gt_tx)), ' now max: ', np.max(np.abs(tx - gt_tx)))\n",
    "    # print('ty: ', ty, ' gt ty:', gt_ty,  ' ty diff: ', np.abs(ty - gt_ty), ' in average: ', np.mean(np.abs(ty - gt_ty)), 'origin max: ',np.max(np.abs(gt_ty)), ' now max: ', np.max(np.abs(ty - gt_ty)))\n",
    "    # print('tz: ', tz, ' gt tz:', gt_tz,  ' tz diff: ', np.abs(tz - gt_tz), ' in average: ', np.mean(np.abs(tz - gt_tz)), 'origin max: ',np.max(np.abs(gt_tz)), ' now max: ', np.max(np.abs(tz - gt_tz)))\n",
    "    # print('rx: ', rx, ' gt rx:', gt_rx,  ' rx diff: ', np.abs(rx - gt_rx), ' in average: ', np.mean(np.abs(rx - gt_rx)), 'origin max: ',np.max(np.abs(gt_rx)), ' now max: ', np.max(np.abs(rx - gt_rx)))\n",
    "    # print('ry: ', ry, ' gt ry:', gt_ry,  ' ry diff: ', np.abs(ry - gt_ry), ' in average: ', np.mean(np.abs(ry - gt_ry)), 'origin max: ',np.max(np.abs(gt_ry)), ' now max: ', np.max(np.abs(ry - gt_ry)))\n",
    "    # print('rz: ', rz, ' gt rz:', gt_rz,  ' rz diff: ', np.abs(rz - gt_rz), ' in average: ', np.mean(np.abs(rz - gt_rz)), 'origin max: ',np.max(np.abs(gt_rz)), ' now max: ', np.max(np.abs(rz - gt_rz)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
